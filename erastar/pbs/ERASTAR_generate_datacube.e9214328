2024-04-29 18:00:05,251 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
2024-04-29 18:00:05,252 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
2024-04-29 18:00:05,252 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
2024-04-29 18:00:05,254 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing
2024-04-29 18:00:06,051 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x2aaaf5644950>>, <Task finished name='Task-3018852' coro=<SpecCluster._correct_state_internal() done, defined at /home1/datawork/gcaer/conda-env/pangeo-forge-recipes-0.9-env/lib/python3.12/site-packages/distributed/deploy/spec.py:346> exception=TimeoutError()>)
Traceback (most recent call last):
  File "/home1/datawork/gcaer/conda-env/pangeo-forge-recipes-0.9-env/lib/python3.12/site-packages/distributed/utils.py", line 1935, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datawork/gcaer/conda-env/pangeo-forge-recipes-0.9-env/lib/python3.12/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
          ^^^^^^^^^^
  File "/home1/datawork/gcaer/conda-env/pangeo-forge-recipes-0.9-env/lib/python3.12/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
TimeoutError
2024-04-29 18:00:07,789 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 35803 exit status was already read will report exitcode 255
